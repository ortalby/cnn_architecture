{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on minimal_net cs231n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss 1.872996\n",
      "iteration 10: loss 0.243096\n",
      "iteration 20: loss 0.131005\n",
      "iteration 30: loss 0.093438\n",
      "iteration 40: loss 0.075212\n",
      "iteration 50: loss 0.064682\n",
      "iteration 60: loss 0.057941\n",
      "iteration 70: loss 0.053323\n",
      "iteration 80: loss 0.050001\n",
      "iteration 90: loss 0.047523\n",
      "iteration 100: loss 0.045621\n",
      "iteration 110: loss 0.044126\n",
      "iteration 120: loss 0.042928\n",
      "iteration 130: loss 0.041952\n",
      "iteration 140: loss 0.041146\n",
      "iteration 150: loss 0.040471\n",
      "iteration 160: loss 0.039899\n",
      "iteration 170: loss 0.039411\n",
      "iteration 180: loss 0.038989\n",
      "iteration 190: loss 0.038621\n",
      "[[-3.23369748  5.00542509]\n",
      " [ 1.40618408  1.22956322]\n",
      " [ 1.91497094 -1.18614417]]\n",
      "[[ 0.41505245 -0.41505245]]\n",
      " for [0,0,1] -  [[0.9807578 0.0192422]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import exp, array, random, dot\n",
    "\n",
    "#in this example we will train linear classifier and compare resultes witb nn\n",
    "\n",
    "\n",
    "training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "training_set_outputs = array([[0, 1, 1, 0]])\n",
    "#Train a Linear Classifier\n",
    "\n",
    "#Initialize randomly weights vector(size 2)\n",
    "np.random.seed(0)\n",
    "W =np.random.randn(3,2)\n",
    "b = np.zeros((1,2))\n",
    "\n",
    "#some hyperparameters\n",
    "\n",
    "step_size = 1e-0\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "# gradient descent loop\n",
    "num_examples = training_set_inputs.shape[0]\n",
    "for i in range(200):\n",
    "    # evaluate class scores, [N x K]\n",
    "    scores = np.dot(training_set_inputs, W) + b\n",
    "    # compute the class probabilities\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # [N x K]\n",
    "\n",
    "    # compute the loss: average cross-entropy loss and regularization\n",
    "    corect_logprobs = -np.log(probs[range(num_examples),training_set_outputs])\n",
    "    data_loss = np.sum(corect_logprobs) / num_examples\n",
    "    reg_loss = 0.5 * reg * np.sum(W * W)\n",
    "    loss = data_loss + reg_loss\n",
    "    if i % 10 == 0:\n",
    "        print(\"iteration %d: loss %f\" % (i, loss))\n",
    "\n",
    "    # compute the gradient on scores\n",
    "    dscores = probs\n",
    "    dscores[range(num_examples),training_set_outputs] -= 1\n",
    "    dscores /= num_examples\n",
    "\n",
    "    # backpropate the gradient to the parameters (W,b)\n",
    "    dW = np.dot(training_set_inputs.T, dscores)\n",
    "    db = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "    dW += reg * W  # regularization gradient\n",
    "\n",
    "    # perform a parameter update\n",
    "    W += -step_size * dW\n",
    "    b += -step_size * db\n",
    "\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "\n",
    "scores = np.dot([0,0,1], W) + b\n",
    "# compute the class probabilities\n",
    "exp_scores = np.exp(scores)\n",
    "probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # [N x K]\n",
    "print(' for [0,0,1] - ', probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
